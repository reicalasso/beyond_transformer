{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSM Debug Mode Demonstration\n",
    "\n",
    "This notebook demonstrates the debug mode functionality for Neural State Machine models, including step-by-step state tracking and memory operation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path().cwd().parent.parent))\n",
    "\n",
    "# Import debug tools\n",
    "from nsm.utils.debugger import NSMDebugger\n",
    "from nsm.modules.debuggable_components import (\n",
    "    DebuggableTokenToStateRouter,\n",
    "    DebuggableStateManager,\n",
    "    DebuggableStatePropagator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up Debug Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create debugger\n",
    "debugger = NSMDebugger(\"nsm_debug_logs\", verbose=True)\n",
    "debugger.enable_debug()\n",
    "\n",
    "print(\"âœ… NSM Debugger initialized and enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Debuggable Component Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create debuggable components\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Token-to-state router\n",
    "router = DebuggableTokenToStateRouter(\n",
    "    token_dim=64,\n",
    "    state_dim=128,\n",
    "    num_states=8,\n",
    "    num_heads=4,\n",
    "    debug_mode=True\n",
    ")\n",
    "router.set_debugger(debugger)\n",
    "\n",
    "# State manager\n",
    "state_manager = DebuggableStateManager(\n",
    "    state_dim=128,\n",
    "    max_states=16,\n",
    "    initial_states=8,\n",
    "    debug_mode=True\n",
    ")\n",
    "state_manager.set_debugger(debugger)\n",
    "\n",
    "# State propagator\n",
    "propagator = DebuggableStatePropagator(\n",
    "    state_dim=128,\n",
    "    gate_type='gru',\n",
    "    enable_communication=True,\n",
    "    debug_mode=True\n",
    ")\n",
    "propagator.set_debugger(debugger)\n",
    "\n",
    "print(\"âœ… Debuggable components created and connected to debugger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step-by-Step Processing with Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "batch_size = 2\n",
    "seq_len = 10\n",
    "token_dim = 64\n",
    "state_dim = 128\n",
    "num_states = 8\n",
    "\n",
    "# Create sample inputs\n",
    "tokens = torch.randn(batch_size, seq_len, token_dim)\n",
    "states = torch.randn(batch_size, num_states, state_dim)\n",
    "\n",
    "print(f\"Input tokens shape: {tokens.shape}\")\n",
    "print(f\"Input states shape: {states.shape}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Sequence length: {seq_len}\")\n",
    "print(f\"Number of states: {num_states}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Token-to-state routing\n",
    "print(\"\\n=== Step 1: Token-to-State Routing ===\")\n",
    "\n",
    "routed_tokens, routing_weights = router(tokens, states)\n",
    "\n",
    "print(f\"Routed tokens shape: {routed_tokens.shape}\")\n",
    "print(f\"Routing weights shape: {routing_weights.shape}\")\n",
    "print(f\"Average routing weight: {routing_weights.mean().item():.4f}\")\n",
    "print(f\"Max routing weight: {routing_weights.max().item():.4f}\")\n",
    "print(f\"Min routing weight: {routing_weights.min().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: State management\n",
    "print(\"\\n=== Step 2: State Management ===\")\n",
    "\n",
    "# Get active states\n",
    "active_states = state_manager()\n",
    "print(f\"Active states shape: {active_states.shape}\")\n",
    "print(f\"Active states count: {state_manager.get_active_count()}\")\n",
    "\n",
    "# Get importance scores\n",
    "importance_scores = state_manager.get_importance_scores()\n",
    "print(f\"Importance scores range: [{importance_scores.min().item():.4f}, {importance_scores.max().item():.4f}]\")\n",
    "print(f\"Average importance score: {importance_scores.mean().item():.4f}\")\n",
    "\n",
    "# Try to allocate more states\n",
    "allocated = state_manager.allocate_states(2)\n",
    "print(f\"Allocated states: {allocated}\")\n",
    "print(f\"New active count: {state_manager.get_active_count()}\")\n",
    "\n",
    "# Try to prune low-importance states\n",
    "pruned = state_manager.prune_low_importance_states()\n",
    "print(f\"Pruned states: {pruned}\")\n",
    "print(f\"Final active count: {state_manager.get_active_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: State propagation\n",
    "print(\"\\n=== Step 3: State Propagation ===\")\n",
    "\n",
    "# Get current states\n",
    "current_states = state_manager()\n",
    "current_states_expanded = current_states.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "# Propagate states\n",
    "updated_states = propagator(current_states_expanded, routed_tokens)\n",
    "\n",
    "print(f\"Previous states shape: {current_states_expanded.shape}\")\n",
    "print(f\"Updated states shape: {updated_states.shape}\")\n",
    "print(f\"State difference mean: {torch.mean(updated_states - current_states_expanded).item():.6f}\")\n",
    "print(f\"State difference std: {torch.std(updated_states - current_states_expanded).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory Operation Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate memory read/write operations\n",
    "print(\"\\n=== Memory Operation Monitoring ===\")\n",
    "\n",
    "# Log a memory read operation\n",
    "read_data = torch.randn(8, 128)\n",
    "attention_weights = torch.softmax(torch.randn(8), dim=0)\n",
    "\n",
    "debugger.log_memory_operation(\n",
    "    'read', 'memory_slot_0',\n",
    "    read_data=read_data,\n",
    "    attention_weights=attention_weights,\n",
    "    operation_info={'purpose': 'retrieve_context', 'priority': 'high'}\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory read operation logged\")\n",
    "\n",
    "# Log a memory write operation\n",
    "write_data = torch.randn(8, 128)\n",
    "erase_vector = torch.sigmoid(torch.randn(8, 128))\n",
    "\n",
    "debugger.log_memory_operation(\n",
    "    'write', 'memory_slot_1',\n",
    "    write_data=write_data,\n",
    "    attention_weights=erase_vector,\n",
    "    operation_info={'purpose': 'store_result', 'priority': 'medium'}\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory write operation logged\")\n",
    "\n",
    "# Log a memory erase operation\n",
    "debugger.log_memory_operation(\n",
    "    'erase', 'memory_slot_2',\n",
    "    write_data=erase_vector,\n",
    "    operation_info={'purpose': 'clear_old_data', 'priority': 'low'}\n",
    ")\n",
    "\n",
    "print(\"âœ… Memory erase operation logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Operation Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate attention operations\n",
    "print(\"\\n=== Attention Operation Monitoring ===\")\n",
    "\n",
    "# Log token-to-state attention\n",
    "attention_weights = torch.softmax(torch.randn(10, 8), dim=-1)  // 10 tokens, 8 states\n",
    "\n",
    "debugger.log_attention_operation(\n",
    "    'token_to_state', 'input_sequence', 'state_nodes',\n",
    "    attention_weights=attention_weights,\n",
    "    attended_values=torch.randn(10, 8),\n",
    "    operation_info={'layer': 'encoding', 'head': 'all'}\n",
    ")\n",
    "\n",
    "print(\"âœ… Token-to-state attention operation logged\")\n",
    "\n",
    "// Log state-to-state attention\n",
    "state_attention = torch.softmax(torch.randn(8, 8), dim=-1)  // 8 states\n",
    "\n",
    "debugger.log_attention_operation(\n",
    "    'state_to_state', 'state_nodes', 'state_nodes',\n",
    "    attention_weights=state_attention,\n",
    "    attended_values=torch.randn(8, 8),\n",
    "    operation_info={'layer': 'communication', 'head': 'all'}\n",
    ")\n",
    "\n",
    "print(\"âœ… State-to-state attention operation logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. State Update Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate state updates\n",
    "print(\"\\n=== State Update Monitoring ===\")\n",
    "\n",
    "# Log state updates\n",
    "old_state = torch.randn(6, 128)\n",
    "new_state = old_state + torch.randn(6, 128) * 0.1\n",
    "\n",
    "debugger.log_state_update(\n",
    "    'StateManager', old_state, new_state,\n",
    "    update_info={'update_type': 'propagation', 'learning_rate': 0.001}\n",
    ")\n",
    "\n",
    "print(\"âœ… State update operation logged\")\n",
    "\n",
    "# Calculate statistics\n",
    "state_diff = new_state - old_state\n",
    "print(f\"State update statistics:\")\n",
    "print(f\"  - Mean change: {state_diff.mean().item():.6f}\")\n",
    "print(f\"  - Std change: {state_diff.std().item():.6f}\")\n",
    "print(f\"  - Max change: {state_diff.abs().max().item():.6f}\")\n",
    "print(f\"  - Min change: {state_diff.abs().min().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Debug Summary and Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Print debug summary\n",
    "print(\"\\n=== Debug Summary ===\")\n",
    "debugger.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Analyze logged data\n",
    "print(\"\\n=== Log Analysis ===\")\n",
    "log_data = debugger.log_data\n",
    "\n",
    "print(f\"Total log entries: {len(log_data)}\")\n",
    "\n",
    "// Analyze step types\n",
    "step_types = {}\n",
    "for entry in log_data:\n",
    "    step_name = entry['step_name']\n",
    "    step_types[step_name] = step_types.get(step_name, 0) + 1\n",
    "\n",
    "print(\"\\nStep type breakdown:\")\n",
    "for step_name, count in sorted(step_types.items()):\n",
    "    print(f\"  {step_name}: {count}\")\n",
    "\n",
    "// Analyze memory operations\n",
    "memory_ops = [entry for entry in log_data if 'memory_operation' in entry['data']]\n",
    "print(f\"\\nMemory operations: {len(memory_ops)}\")\n",
    "\n",
    "// Analyze attention operations\n",
    "attention_ops = [entry for entry in log_data if 'attention_operation' in entry['data']]\n",
    "print(f\"Attention operations: {len(attention_ops)}\")\n",
    "\n",
    "// Analyze state updates\n",
    "state_updates = [entry for entry in log_data if 'state_update' in entry['data']]\n",
    "print(f\"State updates: {len(state_updates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Save debug log\n",
    "print(\"\\n=== Log Saving ===\")\n",
    "log_file = debugger.save_debug_log()\n",
    "print(f\"Debug log saved to: {log_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Debug Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Custom step logging\n",
    "print(\"\\n=== Custom Step Logging ===\")\n",
    "\n",
    "// Log a custom step\n",
    "custom_data = {\n",
    "    'processing_stage': 'custom_analysis',\n",
    "    'parameters': {\n",
    "        'temperature': 1.0,\n",
    "        'top_k': 50,\n",
    "        'top_p': 0.9\n",
    "    },\n",
    "    'metrics': {\n",
    "        'perplexity': 15.67,\n",
    "        'accuracy': 0.892\n",
    "    }\n",
    "}\n",
    "\n",
    "debugger.log_step(\n",
    "    'custom_analysis',\n",
    "    custom_data,\n",
    "    step_info={'model_version': 'v1.2', 'experiment_id': 'exp_001'}\n",
    ")\n",
    "\n",
    "print(\"âœ… Custom step logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Conditional logging based on thresholds\n",
    "print(\"\\n=== Conditional Logging ===\")\n",
    "\n",
    "def conditional_log_check(state_diff_norm, threshold=0.5):\n",
    "    \"\"\"Conditionally log based on state change magnitude.\"\"\"\n",
    "    if state_diff_norm > threshold:\n",
    "        debugger.log_step(\n",
    "            'large_state_change_detected',\n",
    "            {'state_diff_norm': state_diff_norm},\n",
    "            step_info={'warning': 'Significant state change detected', 'threshold': threshold}\n",
    "        )\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "// Test conditional logging\n",
    "large_change = 0.8\n",
    "small_change = 0.2\n",
    "\n",
    "logged_large = conditional_log_check(large_change, 0.5)\n",
    "logged_small = conditional_log_check(small_change, 0.5)\n",
    "\n",
    "print(f\"Large change ({large_change}) logged: {logged_large}\")\n",
    "print(f\"Small change ({small_change}) logged: {logged_small}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Debug Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Final debug summary\n",
    "print(\"\\n=== Final Debug Summary ===\")\n",
    "debugger.print_summary()\n",
    "\n",
    "// Save final log\n",
    "final_log_file = debugger.save_debug_log()\n",
    "print(f\"\\nFinal debug log saved to: {final_log_file}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ NSM Debug Mode Demonstration Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the NSM debug mode functionality:\n",
    "\n",
    "### Key Features Implemented:\n",
    "\n",
    "1. **Step-by-Step State Tracking**:\n",
    "   - Each processing step is logged with detailed information\n",
    "   - Components can log their internal operations\n",
    "   - Timestamped and indexed for chronological analysis\n",
    "\n",
    "2. **Memory Operation Monitoring**:\n",
    "   - Read, write, and erase operations are tracked\n",
    "   - Attention weights used for memory access are recorded\n",
    "   - Memory slot identification and operation purposes\n",
    "\n",
    "3. **Attention Operation Monitoring**:\n",
    "   - Token-to-state and state-to-state attention tracking\n",
    "   - Attention weight patterns and attended values\n",
    "   - Layer and head information for multi-head attention\n",
    "\n",
    "4. **State Update Monitoring**:\n",
    "   - Before and after state comparisons\n",
    "   - Statistical analysis of state changes\n",
    "   - Update type and parameter information\n",
    "\n",
    "5. **Comprehensive Logging System**:\n",
    "   - JSON-based structured logging\n",
    "   - Detailed tensor statistics (mean, std, min, max)\n",
    "   - Metadata and timestamping\n",
    "   - Automatic log file generation\n",
    "\n",
    "### Debug Modes Available:\n",
    "\n",
    "- **Verbose Mode**: Real-time printing of debug information\n",
    "- **Silent Mode**: Logging without console output\n",
    "- **Conditional Logging**: Threshold-based selective logging\n",
    "- **Custom Logging**: User-defined step and data logging\n",
    "\n",
    "### Benefits for Development:\n",
    "\n",
    "âœ… **Transparent Model Behavior**: Clear insight into internal operations\n",
    "\n",
    "âœ… **Debugging Assistance**: Easy identification of issues in processing\n",
    "\n",
    "âœ… **Performance Analysis**: Detailed timing and resource usage tracking\n",
    "\n",
    "âœ… **Research Support**: Quantitative analysis of model behavior\n",
    "\n",
    "âœ… **Educational Tool**: Understanding of complex NSM mechanics\n",
    "\n",
    "âœ… **Production Monitoring**: Real-time monitoring in deployed systems\n",
    "\n",
    "The debug mode provides comprehensive visibility into Neural State Machine operations, making it easier to understand, debug, and optimize these complex models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
