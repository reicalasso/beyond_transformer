{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural State Machine Visualization Tools\n",
    "\n",
    "This notebook demonstrates the visualization tools for interpreting Neural State Machine models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path().cwd().parent))\n",
    "\n",
    "# Import visualization tools\n",
    "from nsm.utils.visualizer import NSMVisualizer\n",
    "from nsm.utils.advanced_visualizer import AdvancedNSMVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Visualization Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic visualizer\n",
    "visualizer = NSMVisualizer(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample attention weights\n",
    "attention_weights = torch.softmax(torch.randn(8, 8), dim=-1)\n",
    "\n",
    "# Sample memory content\n",
    "memory_content = torch.randn(16, 20)\n",
    "\n",
    "# Sample state evolution\n",
    "states = [torch.randn(8, 16) for _ in range(5)]\n",
    "\n",
    "# Sample importance scores\n",
    "importance_scores = torch.sigmoid(torch.randn(16))\n",
    "\n",
    "print(\"Sample data generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot attention map\n",
    "fig1 = visualizer.plot_attention_map(\n",
    "    attention_weights, \n",
    "    title=\"Sample Attention Map\",\n",
    "    x_labels=[f\"Pos{i}\" for i in range(8)],\n",
    "    y_labels=[f\"Query{i}\" for i in range(8)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory content\n",
    "fig2 = visualizer.plot_memory_content(\n",
    "    memory_content,\n",
    "    title=\"Sample Memory Content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot state evolution\n",
    "fig3 = visualizer.plot_state_evolution(\n",
    "    states,\n",
    "    title=\"Sample State Evolution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot memory importance\n",
    "fig4 = visualizer.plot_memory_importance(\n",
    "    importance_scores,\n",
    "    title=\"Sample Memory Importance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced NSM-Specific Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create advanced visualizer\n",
    "advanced_visualizer = AdvancedNSMVisualizer(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate advanced sample data\n",
    "\n",
    "# Token-to-state routing weights\n",
    "routing_weights = torch.softmax(torch.randn(12, 8), dim=-1)  # 12 tokens, 8 states\n",
    "\n",
    "# State-to-state communication\n",
    "state_attention = torch.softmax(torch.randn(8, 8), dim=-1)  # 8 states\n",
    "\n",
    "# Memory read/write operations\n",
    "read_weights = torch.softmax(torch.randn(10), dim=0)  // 10 memory slots\n",
    "write_weights = torch.softmax(torch.randn(10), dim=0)\n",
    "\n",
    "# State dynamics\n",
    "state_trajectories = [torch.randn(6, 12) for _ in range(10)]  // 6 states, 12 dims, 10 steps\n",
    "\n",
    "print(\"Advanced sample data generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Plot token-to-state routing\n",
    "fig5 = advanced_visualizer.plot_token_to_state_routing(\n",
    "    routing_weights,\n",
    "    token_labels=[f\"T{i}\" for i in range(12)],\n",
    "    state_labels=[f\"S{i}\" for i in range(8)],\n",
    "    title=\"Token-to-State Routing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Plot state-to-state communication\n",
    "fig6 = advanced_visualizer.plot_state_communication(\n",
    "    state_attention,\n",
    "    state_labels=[f\"State{i}\" for i in range(8)],\n",
    "    title=\"State-to-State Communication\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Plot memory read/write operations\n",
    "fig7 = advanced_visualizer.plot_memory_read_write_operations(\n",
    "    read_weights, write_weights,\n",
    "    memory_slots=[f\"Slot{i}\" for i in range(10)],\n",
    "    title=\"Memory Read/Write Operations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Plot state dynamics\n",
    "fig8 = advanced_visualizer.plot_state_dynamics(\n",
    "    state_trajectories,\n",
    "    state_labels=[f\"S{i}\" for i in range(6)],\n",
    "    metrics=['norm', 'mean', 'std'],\n",
    "    title=\"State Dynamics Over Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Visualization Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create comprehensive visualization data\n",
    "visualization_data = {\n",
    "    'attention_weights': attention_weights,\n",
    "    'routing_weights': routing_weights,\n",
    "    'memory_content': memory_content,\n",
    "    'state_attention': state_attention,\n",
    "    'importance_scores': importance_scores\n",
    "};\n",
    "\n",
    "// Generate comprehensive report\n",
    "report_dir = advanced_visualizer.create_comprehensive_report(\n",
    "    visualization_data,\n",
    "    save_dir=\"visualization_reports\"\n",
    ");\n",
    "\n",
    "print(f\"Comprehensive report generated in: {report_dir}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create interactive summary\n",
    "summary_df = visualizer.create_interactive_summary(visualization_data);\n",
    "summary_df;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Analyze attention patterns\n",
    "attention_np = attention_weights.detach().cpu().numpy();\n",
    "\n",
    "print(\"Attention Pattern Analysis:\");\n",
    "print(f\"  - Max attention weight: {np.max(attention_np):.4f}\");\n",
    "print(f\"  - Min attention weight: {np.min(attention_np):.4f}\");\n",
    "print(f\"  - Mean attention weight: {np.mean(attention_np):.4f}\");\n",
    "print(f\"  - Std attention weight: {np.std(attention_np):.4f}\");\n",
    "\n",
    "// Find strongest attention connections\n",
    "max_indices = np.unravel_index(np.argmax(attention_np), attention_np.shape);\n",
    "print(f\"  - Strongest connection: Query {max_indices[0]} â†’ Key {max_indices[1]} = {attention_np[max_indices]:.4f}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Analyze memory content\n",
    "memory_np = memory_content.detach().cpu().numpy();\n",
    "\n",
    "print(\"\\nMemory Content Analysis:\");\n",
    "print(f\"  - Memory slots: {memory_np.shape[0]}\");\n",
    "print(f\"  - Memory dimensions: {memory_np.shape[1]}\");\n",
    "print(f\"  - Max value: {np.max(memory_np):.4f}\");\n",
    "print(f\"  - Min value: {np.min(memory_np):.4f}\");\n",
    "print(f\"  - Mean value: {np.mean(memory_np):.4f}\");\n",
    "print(f\"  - Std value: {np.std(memory_np):.4f}\");\n",
    "\n",
    "// Find most active memory slots\n",
    "slot_means = np.mean(np.abs(memory_np), axis=1);\n",
    "most_active_slot = np.argmax(slot_means);\n",
    "print(f\"  - Most active slot: {most_active_slot} (mean abs: {slot_means[most_active_slot]:.4f})\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Visualization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create custom attention pattern visualization\n",
    "function plot_custom_attention_pattern(pattern_type=\"diagonal\") {\n",
    "    \"\"\"Create and visualize custom attention patterns.\"\"\"\n",
    "    size = 10;\n",
    "    \n",
    "    if (pattern_type == \"diagonal\") {\n",
    "        // Diagonal pattern\n",
    "        pattern = torch.eye(size);\n",
    "    } else if (pattern_type == \"local\") {\n",
    "        // Local attention pattern\n",
    "        pattern = torch.zeros(size, size);\n",
    "        for (i in range(size)) {\n",
    "            for (j in range(max(0, i-2), min(size, i+3))) {\n",
    "                pattern[i, j] = 1.0;\n",
    "            }\n",
    "        }\n",
    "    } else if (pattern_type == \"random\") {\n",
    "        // Random pattern\n",
    "        pattern = torch.softmax(torch.randn(size, size), dim=-1);\n",
    "    } else {\n",
    "        pattern = torch.ones(size, size) / size;\n",
    "    }\n",
    "    \n",
    "    // Normalize\n",
    "    pattern = torch.softmax(pattern, dim=-1);\n",
    "    \n",
    "    // Plot\n",
    "    fig = visualizer.plot_attention_map(\n",
    "        pattern,\n",
    "        title=f\"Custom Attention Pattern: {pattern_type.capitalize()}\",\n",
    "        x_labels=[f\"P{i}\" for i in range(size)],\n",
    "        y_labels=[f\"Q{i}\" for i in range(size)]\n",
    "    );\n",
    "    \n",
    "    return fig;\n",
    "}\n",
    "\n",
    "// Test custom patterns\n",
    "fig9 = plot_custom_attention_pattern(\"diagonal\");\n",
    "fig10 = plot_custom_attention_pattern(\"local\");\n",
    "fig11 = plot_custom_attention_pattern(\"random\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create memory evolution visualization\n",
    "function plot_memory_evolution(num_steps=5) {\n",
    "    \"\"\"Visualize how memory content evolves over time.\"\"\"\n",
    "    torch.manual_seed(123);\n",
    "    \n",
    "    // Simulate memory evolution\n",
    "    initial_memory = torch.randn(8, 12);\n",
    "    memory_states = [initial_memory];\n",
    "    \n",
    "    for (i in range(num_steps - 1)) {\n",
    "        // Simulate some change\n",
    "        change = torch.randn(8, 12) * 0.1;\n",
    "        new_memory = memory_states[-1] + change;\n",
    "        memory_states.append(new_memory);\n",
    "    }\n",
    "    \n",
    "    // Plot evolution\n",
    "    fig = visualizer.plot_state_evolution(\n",
    "        memory_states,\n",
    "        title=\"Memory Content Evolution Over Time\"\n",
    "    );\n",
    "    \n",
    "    return fig;\n",
    "}\n",
    "\n",
    "// Test memory evolution\n",
    "fig12 = plot_memory_evolution(6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Basic Visualization Tools**:\n",
    "   - Attention maps\n",
    "   - Memory content visualization\n",
    "   - State evolution tracking\n",
    "   - Memory importance scoring\n",
    "\n",
    "2. **Advanced NSM-Specific Visualizations**:\n",
    "   - Token-to-state routing\n",
    "   - State-to-state communication\n",
    "   - Memory read/write operations\n",
    "   - State dynamics over time\n",
    "\n",
    "3. **Comprehensive Reporting**:\n",
    "   - Automated report generation\n",
    "   - Interactive data analysis\n",
    "   - Statistical summaries\n",
    "\n",
    "4. **Custom Visualization Examples**:\n",
    "   - Custom attention patterns\n",
    "   - Memory evolution tracking\n",
    "\n",
    "These tools help interpret the internal workings of Neural State Machine models and provide insights into their decision-making processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}