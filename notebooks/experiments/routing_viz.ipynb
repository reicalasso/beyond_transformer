{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token-to-State Routing Visualization\n",
    "\n",
    "This notebook visualizes how input tokens are routed to different state nodes in a Parallel Unified Linear State Engine. We'll create heatmaps showing which tokens attend to which states and optionally overlay importance scores of state nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from pulse.components import TokenToStateRouter, StateManager\n",
    "from pulse.models.simple_pulse import Simplepulse\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Sample Model\n",
    "\n",
    "We'll create a sample pulse model to demonstrate routing visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample pulse model\n",
    "model = Simplepulse(\n",
    "    input_dim=128,      # Input dimension\n",
    "    state_dim=64,       # State dimension\n",
    "    num_states=16,      # Number of states\n",
    "    output_dim=10,      # Classification output\n",
    "    gate_type='gru'     # Gating mechanism\n",
    ").to(device)\n",
    "\n",
    "# Create a TokenToStateRouter for visualization\n",
    "router = TokenToStateRouter(\n",
    "    token_dim=128,\n",
    "    state_dim=64,\n",
    "    num_states=16,\n",
    "    num_heads=4\n",
    ").to(device)\n",
    "\n",
    "# Create a StateManager for importance scores\n",
    "state_manager = StateManager(\n",
    "    state_dim=64,\n",
    "    max_states=16,\n",
    "    initial_states=16,\n",
    "    prune_threshold=0.3\n",
    ")\n",
    "\n",
    "print(\"Model components created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "We'll create synthetic token sequences to visualize the routing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample tokens\n",
    "batch_size = 4\n",
    "seq_len = 20\n",
    "token_dim = 128\n",
    "num_states = 16\n",
    "state_dim = 64\n",
    "\n",
    "# Create sample token sequences\n",
    "sample_tokens = torch.randn(batch_size, seq_len, token_dim).to(device)\n",
    "sample_states = torch.randn(batch_size, num_states, state_dim).to(device)\n",
    "\n",
    "print(f\"Sample tokens shape: {sample_tokens.shape}\")\n",
    "print(f\"Sample states shape: {sample_states.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Routing Patterns\n",
    "\n",
    "Let's create heatmaps showing how tokens are routed to states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_routing_heatmap(tokens, states, router, example_idx=0, title=\"Token-to-State Routing Heatmap\"):\n",
    "    \"\"\"\n",
    "    Visualize the routing heatmap for a specific example in the batch.\n",
    "    \n",
    "    Args:\n",
    "        tokens (torch.Tensor): Input tokens [batch_size, seq_len, token_dim]\n",
    "        states (torch.Tensor): State vectors [batch_size, num_states, state_dim]\n",
    "        router (TokenToStateRouter): Router module\n",
    "        example_idx (int): Index of example in batch to visualize\n",
    "        title (str): Title for the plot\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get routing weights\n",
    "        _, routing_weights = router(tokens, states)\n",
    "        \n",
    "        # Select specific example\n",
    "        example_weights = routing_weights[example_idx].cpu().numpy()\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            example_weights,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='viridis',\n",
    "            cbar=True,\n",
    "            xticklabels=[f'State {i}' for i in range(example_weights.shape[1])],\n",
    "            yticklabels=[f'Token {i}' for i in range(example_weights.shape[0])]\n",
    "        )\n",
    "        plt.title(title)\n",
    "        plt.xlabel('State Nodes')\n",
    "        plt.ylabel('Tokens')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return example_weights\n",
    "\n",
    "# Visualize routing for first example\n",
    "routing_weights = visualize_routing_heatmap(\n",
    "    sample_tokens, \n",
    "    sample_states, \n",
    "    router, \n",
    "    example_idx=0,\n",
    "    title=\"Token-to-State Routing Heatmap (Example 0)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Routing with State Importance Overlay\n",
    "\n",
    "Let's enhance the visualization by overlaying state importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_routing_with_importance(tokens, states, router, state_manager, example_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize routing heatmap with state importance scores overlaid.\n",
    "    \n",
    "    Args:\n",
    "        tokens (torch.Tensor): Input tokens [batch_size, seq_len, token_dim]\n",
    "        states (torch.Tensor): State vectors [batch_size, num_states, state_dim]\n",
    "        router (TokenToStateRouter): Router module\n",
    "        state_manager (StateManager): State manager with importance scores\n",
    "        example_idx (int): Index of example in batch to visualize\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get routing weights\n",
    "        _, routing_weights = router(tokens, states)\n",
    "        \n",
    "        # Select specific example\n",
    "        example_weights = routing_weights[example_idx].cpu().numpy()\n",
    "        \n",
    "        # Get state importance scores\n",
    "        importance_scores = state_manager.get_importance_scores().cpu().numpy()\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Plot routing heatmap\n",
    "        sns.heatmap(\n",
    "            example_weights,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='viridis',\n",
    "            cbar=True,\n",
    "            xticklabels=[f'State {i}' for i in range(example_weights.shape[1])],\n",
    "            yticklabels=[f'Token {i}' for i in range(example_weights.shape[0])],\n",
    "            ax=ax1\n",
    "        )\n",
    "        ax1.set_title(f'Token-to-State Routing (Example {example_idx})')\n",
    "        ax1.set_xlabel('State Nodes')\n",
    "        ax1.set_ylabel('Tokens')\n",
    "        \n",
    "        # Plot state importance\n",
    "        bars = ax2.bar(range(len(importance_scores)), importance_scores, color='skyblue')\n",
    "        ax2.set_xlabel('State Nodes')\n",
    "        ax2.set_ylabel('Importance Score')\n",
    "        ax2.set_title('State Importance Scores')\n",
    "        ax2.set_xticks(range(len(importance_scores)))\n",
    "        ax2.set_xticklabels([f'State {i}' for i in range(len(importance_scores))], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.2f}',\n",
    "                    ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return example_weights, importance_scores\n",
    "\n",
    "# Visualize routing with importance scores\n",
    "routing_weights, importance_scores = visualize_routing_with_importance(\n",
    "    sample_tokens,\n",
    "    sample_states,\n",
    "    router,\n",
    "    state_manager,\n",
    "    example_idx=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch-Level Routing Analysis\n",
    "\n",
    "Let's analyze routing patterns across the entire batch to identify trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch_routing(tokens, states, router):\n",
    "    \"\"\"\n",
    "    Analyze routing patterns across the entire batch.\n",
    "    \n",
    "    Args:\n",
    "        tokens (torch.Tensor): Input tokens [batch_size, seq_len, token_dim]\n",
    "        states (torch.Tensor): State vectors [batch_size, num_states, state_dim]\n",
    "        router (TokenToStateRouter): Router module\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get routing weights\n",
    "        _, routing_weights = router(tokens, states)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        routing_weights_np = routing_weights.cpu().numpy()\n",
    "        \n",
    "        # Compute average routing weights across batch\n",
    "        avg_routing_weights = np.mean(routing_weights_np, axis=0)\n",
    "        \n",
    "        # Compute token-level preferences\n",
    "        token_preferences = np.mean(avg_routing_weights, axis=0)  # Average across tokens\n",
    "        \n",
    "        # Compute state-level preferences\n",
    "        state_preferences = np.mean(avg_routing_weights, axis=1)  # Average across states\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        # Average routing heatmap\n",
    "        sns.heatmap(\n",
    "            avg_routing_weights,\n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='viridis',\n",
    "            cbar=True,\n",
    "            xticklabels=[f'State {i}' for i in range(avg_routing_weights.shape[1])],\n",
    "            yticklabels=[f'Token {i}' for i in range(avg_routing_weights.shape[0])],\n",
    "            ax=axes[0]\n",
    "        )\n",
    "        axes[0].set_title('Average Routing Weights (Across Batch)')\n",
    "        axes[0].set_xlabel('State Nodes')\n",
    "        axes[0].set_ylabel('Tokens')\n",
    "        \n",
    "        # Token preferences (which states are preferred overall)\n",
    "        bars = axes[1].bar(range(len(token_preferences)), token_preferences, color='lightcoral')\n",
    "        axes[1].set_xlabel('State Nodes')\n",
    "        axes[1].set_ylabel('Average Attention')\n",
    "        axes[1].set_title('State Preference Across All Tokens')\n",
    "        axes[1].set_xticks(range(len(token_preferences)))\n",
    "        axes[1].set_xticklabels([f'State {i}' for i in range(len(token_preferences))], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.2f}',\n",
    "                        ha='center', va='bottom')\n",
    "        \n",
    "        # State preferences (which tokens attend to states most)\n",
    "        bars = axes[2].bar(range(len(state_preferences)), state_preferences, color='lightgreen')\n",
    "        axes[2].set_xlabel('Tokens')\n",
    "        axes[2].set_ylabel('Average Attention')\n",
    "        axes[2].set_title('Token Attention Distribution')\n",
    "        axes[2].set_xticks(range(len(state_preferences)))\n",
    "        axes[2].set_xticklabels([f'Token {i}' for i in range(len(state_preferences))], rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            axes[2].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.2f}',\n",
    "                        ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return avg_routing_weights, token_preferences, state_preferences\n",
    "\n",
    "# Analyze batch routing\n",
    "avg_weights, token_prefs, state_prefs = analyze_batch_routing(sample_tokens, sample_states, router)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Routing Entropy\n",
    "\n",
    "Let's analyze the entropy of routing patterns to understand how focused or diffuse the routing is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(probs):\n",
    "    \"\"\"\n",
    "    Compute entropy of probability distributions.\n",
    "    \n",
    "    Args:\n",
    "        probs (np.ndarray): Probability distributions\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Entropy values\n",
    "    \"\"\"\n",
    "    # Add small epsilon to avoid log(0)\n",
    "    eps = 1e-8\n",
    "    probs = np.clip(probs, eps, 1.0)\n",
    "    return -np.sum(probs * np.log(probs), axis=-1)\n",
    "\n",
    "def visualize_routing_entropy(tokens, states, router, example_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize the entropy of routing patterns.\n",
    "    \n",
    "    Args:\n",
    "        tokens (torch.Tensor): Input tokens [batch_size, seq_len, token_dim]\n",
    "        states (torch.Tensor): State vectors [batch_size, num_states, state_dim]\n",
    "        router (TokenToStateRouter): Router module\n",
    "        example_idx (int): Index of example in batch to visualize\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get routing weights\n",
    "        _, routing_weights = router(tokens, states)\n",
    "        \n",
    "        # Select specific example\n",
    "        example_weights = routing_weights[example_idx].cpu().numpy()\n",
    "        \n",
    "        # Compute entropy for each token\n",
    "        entropies = compute_entropy(example_weights)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Entropy per token\n",
    "        axes[0].plot(range(len(entropies)), entropies, marker='o', linewidth=2, markersize=6)\n",
    "        axes[0].set_xlabel('Token Index')\n",
    "        axes[0].set_ylabel('Routing Entropy')\n",
    "        axes[0].set_title(f'Routing Entropy per Token (Example {example_idx})')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Histogram of entropies\n",
    "        axes[1].hist(entropies, bins=10, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "        axes[1].set_xlabel('Routing Entropy')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "        axes[1].set_title('Distribution of Routing Entropies')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Average routing entropy: {np.mean(entropies):.3f}\")\n",
    "        print(f\"Min routing entropy: {np.min(entropies):.3f} (most focused routing)\")\n",
    "        print(f\"Max routing entropy: {np.max(entropies):.3f} (most diffuse routing)\")\n",
    "        \n",
    "        return entropies\n",
    "\n",
    "# Visualize routing entropy\n",
    "entropies = visualize_routing_entropy(sample_tokens, sample_states, router, example_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Routing Heads\n",
    "\n",
    "Let's visualize how different routing heads attend to different state nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_routing_heads(tokens, states, router, example_idx=0):\n",
    "    \"\"\"\n",
    "    Visualize routing patterns for individual heads.\n",
    "    \n",
    "    Args:\n",
    "        tokens (torch.Tensor): Input tokens [batch_size, seq_len, token_dim]\n",
    "        states (torch.Tensor): State vectors [batch_size, num_states, state_dim]\n",
    "        router (TokenToStateRouter): Router module\n",
    "        example_idx (int): Index of example in batch to visualize\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get raw routing logits\n",
    "        batch_size, seq_len, token_dim = tokens.shape\n",
    "        num_states = states.shape[1]\n",
    "        \n",
    "        # Compute routing weights\n",
    "        routing_logits = router.router(tokens)  # [batch_size, seq_len, num_states * num_heads]\n",
    "        routing_logits = routing_logits.view(batch_size, seq_len, router.num_heads, num_states)\n",
    "        \n",
    "        # Select specific example and apply softmax to each head\n",
    "        example_logits = routing_logits[example_idx].cpu().numpy()  # [seq_len, num_heads, num_states]\n",
    "        \n",
    "        # Apply softmax to get probabilities for each head\n",
    "        example_weights = np.zeros_like(example_logits)\n",
    "        for head in range(router.num_heads):\n",
    "            # Apply softmax to each token for this head\n",
    "            for token in range(seq_len):\n",
    "                example_weights[token, head, :] = np.exp(example_logits[token, head, :]) / np.sum(np.exp(example_logits[token, head, :]))\n",
    "        \n",
    "        # Create visualization for each head\n",
    "        num_heads = router.num_heads\n",
    "        fig, axes = plt.subplots(1, num_heads, figsize=(5*num_heads, 6))\n",
    "        \n",
    "        if num_heads == 1:\n",
    "            axes = [axes]  # Make it iterable\n",
    "            \n",
    "        # Plot each head\n",
    "        for head in range(num_heads):\n",
    "            # Average across tokens for this head\n",
    "            head_weights = example_weights[:, head, :]  # [seq_len, num_states]\n",
    "            avg_head_weights = np.mean(head_weights, axis=0)  # [num_states]\n",
    "            \n",
    "            bars = axes[head].bar(range(len(avg_head_weights)), avg_head_weights, color=f'C{head}')\n",
    "            axes[head].set_xlabel('State Nodes')\n",
    "            axes[head].set_ylabel('Average Attention')\n",
    "            axes[head].set_title(f'Routing Head {head+1}')\n",
    "            axes[head].set_xticks(range(len(avg_head_weights)))\n",
    "            axes[head].set_xticklabels([f'State {i}' for i in range(len(avg_head_weights))], rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for i, bar in enumerate(bars):\n",
    "                height = bar.get_height()\n",
    "                axes[head].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                               f'{height:.2f}',\n",
    "                               ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return example_weights\n",
    "\n",
    "# Visualize routing heads\n",
    "head_weights = visualize_routing_heads(sample_tokens, sample_states, router, example_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated several ways to visualize token-to-state routing patterns in Parallel Unified Linear State Engines:\n",
    "\n",
    "1. **Routing Heatmaps**: Show which tokens attend to which states\n",
    "2. **Importance Overlay**: Combine routing patterns with state importance scores\n",
    "3. **Batch Analysis**: Analyze routing patterns across the entire batch\n",
    "4. **Routing Entropy**: Measure how focused or diffuse the routing is\n",
    "5. **Routing Heads**: Compare attention patterns across different routing heads\n",
    "\n",
    "These visualizations help understand how information flows through the pulse architecture and can be useful for debugging and model analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}